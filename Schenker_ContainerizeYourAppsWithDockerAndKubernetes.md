# 8. Docker Compose
## 学習内容
- 宣言型と命令型
- マルチサービスアプリケーションの実行
- サービスのスケーリング
- アプリケーションのビルドとプッシュ

## 達成目標
- アプリケーションの定義および実行に用いる命令型アプローチと宣言型アプローチの主な違いを簡単に説明する
- コンテナと Docker Compose サービスの違いを自分の言葉で説明する
- シンプルなマルチサービス アプリケーション向けの Docker Compose YAML ファイルを作成する
- Docker Compose を使用してシンプルなマルチサービス アプリケーションをビルド、プッシュ、デプロイ、破棄する
- Docker Compose を使ってアプリケーション サービスをスケール アップ/スケール ダウンする

## 宣言型と命令型
- **命令型**：システムが従う必要のある正確な方法を特定することで問題を解決
する方法
- **宣言型**: プログラマーが従うべき正確な手順を特定することなく問題を解決
する方法

# 9. オーケストレーター
オーケストレーターに求められる要件

## 目的の状態の調整

オーケストレーターは、サービスが「宣言された」通りの状態であるかを常に監視し、相違を検出すれば、その差を無くすように動作する。
相違の例：
 - コンテナのクラッシュによる、レプリカ数の不足
 - スケールダウンによる、レプリカ数の超過- コンテナイメージのバージョンの相違

## レプリケートされたサービス、グローバルなサービス

### レプリケートされたサービス
特定数のインスタンスで実行する必要があるサービス。例えば、ワーカーノード。

### グローバルなサービス
クラスタに対して割り当てられるサービス。例えば、マスターノード。
>Kubernetesでは、デーモンセットともいう。

## サービス検出
サービスを宣言的に記述するだけで、オーケストレーターが、サービスを実行する最適なノードを選んでくれる。例えば、サービスAからサービスBに通信する場合、サービスAにBのインスタンスを指示しなくても、勝手に利用可能なBのインスタンスを検出し、通信をルーティングしてくれる。このシステムをサービス検出という。

## ルーティング
サービスAからBへのルーティングが可能である。

## 負荷分散
例えば、ラウンドロビンアルゴリズムを用いて、ロードバランサ―がワークロードを分散させる。内部から内部へ、外部から内部へ、のいずれにおいてもオーケストレーターが適切に負荷分散してくれる。

## スケーリング
インスタンスの追加による水平スケーリング、インスタンスのマシンリソースの追加による垂直スケーリング。スケールアップ、ダウンの際には、サービスのすべてのインスタンスが同一のクラスターノード上で分散されるようにしてはいけない。なぜなら、停電時にサービス全体がダウンするから。データセンターをまたいで分散するような高度な負荷分散も、オーケストレーターはできた方が良い。

## 自己復旧
ノードの正常動作していないとき、他のノードにサービスインスタンスをスケジューリングする。アプリケーションが何を以って正常化という定義は、オペレータや開発者にしかわからない。なので、アプリケーションの正常性をHTTP GETなどで（オーケストレーターが）とれるようにしておくのが良い。

## ダウンタイムゼロのデプロイメント
アップデートの方法：
 - ローリングアップデート：サービスを維持しながら、インスタンスを１つ１つ更新していく。
 - カナリアリリース：トラフィックの１％だけ新しいサービスに流し、すべての正常性が確認されたら、１００％にする。
 - ブルーグリーンデプロイメント：新しいバージョン（グリーン）を本番環境に置き、正常だったら、こっちにルーティングする。バグがあったら、古いバージョン（ブルー）にルーティングして、ロールバックする。

## アフィニティと位置認識
特定のノード上で専用ハードウェアが必要なサービスもある。その場合は、特定のサービスがそのノード上でしか動かないようにスケジュールできる。ただし、この場合も複数ノードを用意するなど冗長性を持たせないと、高可用性が損なわれる。

一部のオーケストレーションエンジンは、位置認識もサポートしている。例えば、ノードに、そのデータセンターのラベル`west`、`center`、`east`をつけて、地理的に偏って発生する災害などの要因に対してロバストさを持たせられる。

## セキュリティ
クラスタに参加するノードは、ノード識別情報が暗号化され、ノード間のすべての通信を暗号化する必要がある。そのために、ノードでは、MTLS（Mutual Transport Layer Security）を使用する。クラスターのノードを相互に認証するには、証明書を利用する。証明書は、流出した場合のために、定期的・要求に応じて自動的にローテーションされる。

## ネットワークポリシー
互いに通信しないサービス同士は、ネットワーキングのサンドボックスで隔離した方が良い。ネットワークベースのサンドボックスは、SDN（Software Defined Network）を用いたり、ネットワークポリシーによってアクセス可能なリソース・不可能なリソースを制御することによって実現できる。

## ロールベースのアクセス制御（RBAC）
例えば、開発、品質保証、プロダクト、などのユーザーグループを設定し、アクセス権を設定する。

## 機密情報
APIアクセストークンなどは、サービスのソースコードにハードコーディングしたり、外部構成ファイルに暗号化しないまま記述したらダメ。最近のオーケストレーターには、こうした機密情報を安全に処理してくれる「シークレット」機能があるので、これを使った方が良い。

## コンテンツの信頼性
コンテナイメージが悪意のあるハッカーに改ざんされることもありうる。ソース側でイメージに署名し、ターゲット側で署名を検証することで、イメージが改ざんされていないことを保証できる。

## イントロスペクション
人間が確認して分析できる必要があるものもある。CPU、メモリ、ディスクの使用料など。こうした情報を、利用しやすく、理解しやすい形式で重要な情報を提示する必要がある。
- ログにアクセスできるようにするために、適切な権限を持つユーザにはデバッグのために、各コンテナに対する`exec`アクセス権を付与する必要がある。
- 理想的には、アプリケーションに対するリクエストを追跡し、それが完了するまでのログが分かる方が良い。
- オーケストレーターは、システムパラメータをグラフィカルに表現したダッシュボードを数種類提供すべき。

## Kubernetes
>Kubernetes はもともと Google が設計したもので、その後 Cloud Native Computing
Foundation (CNCF) に寄付されました。Kubernetes は、長年にわたり非常に大規
模なコンテナを運用してきた Google 独自の Borg システムをモデルにしています。
Kubernetes は、Borg から学んだすべての教訓を組み込んだシステムを設計段階から
完全に作り直すという Google の試みによって生まれました。
独自の技術として開発が進められた Borg とは対照的に、Kubernetes は早期の段階
からオープンソース化されました。そのため社外から膨大な数の協力者が参加する
ことになり、わずか数年で Kubernetes を中心とした大規模なエコシステムが展開さ
れることになったため、Google によるこの選択は非常に賢明であったといえます。
コンテナ オーケストレーションの分野では Kubernetes がコミュニティから最も支
持されているオーケストレーターであることに疑いの余地はありません。これまで、ここまで大きな盛り上がりを生み出し、協力者またはアーリー アダプターとしてプロジェクトの成功に有意義な形で積極的に貢献してくれる才能ある多数の人々を引き付けたオーケストレーターはありませんでした。